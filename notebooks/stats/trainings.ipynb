{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import dextra.dna.core as C\n",
    "import dextra.dna.commons as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = P.config.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_weights_path</th>\n",
       "      <th>training_proc</th>\n",
       "      <th>training</th>\n",
       "      <th>trained_at</th>\n",
       "      <th>date_received_stats</th>\n",
       "      <th>committed_at_stats</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>file:///datalake/models/products/word2vec</td>\n",
       "      <td>dextra.dna.commons.processors.products.Learnin...</td>\n",
       "      <td>{'model': {'input_col': 'text_cleaned', 'stop_...</td>\n",
       "      <td>2020-12-08 23:03:18.089839</td>\n",
       "      <td>(2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...</td>\n",
       "      <td>(2020-12-08 21:24:36.162162, 2020-12-08 21:24:...</td>\n",
       "      <td>[(861cbf751715, 2020-12-08 21:24:36.162162), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                         model_weights_path  \\\n",
       "0   word2vec  file:///datalake/models/products/word2vec   \n",
       "\n",
       "                                       training_proc  \\\n",
       "0  dextra.dna.commons.processors.products.Learnin...   \n",
       "\n",
       "                                            training  \\\n",
       "0  {'model': {'input_col': 'text_cleaned', 'stop_...   \n",
       "\n",
       "                  trained_at  \\\n",
       "0 2020-12-08 23:03:18.089839   \n",
       "\n",
       "                                 date_received_stats  \\\n",
       "0  (2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...   \n",
       "\n",
       "                                  committed_at_stats  \\\n",
       "0  (2020-12-08 21:24:36.162162, 2020-12-08 21:24:...   \n",
       "\n",
       "                                             records  \n",
       "0  [(861cbf751715, 2020-12-08 21:24:36.162162), (...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PQT = P.config.lakes.models + '/logs/encoder_trainings.parquet'\n",
    "\n",
    "t = C.io.stream.read(PQT)\n",
    "t.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats from Last Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_training = (\n",
    "    t.drop('records')\n",
    "     .orderBy(F.desc('trained_at'))\n",
    "     .limit(1)\n",
    "     .collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committed_at_stats:\n",
      "  avg: 1607462676.1621423\n",
      "  count: 10003\n",
      "  countDistinct: 1\n",
      "  max: 2020-12-08 21:24:36.162162\n",
      "  min: 2020-12-08 21:24:36.162162\n",
      "date_received_stats:\n",
      "  avg: 1468604431.790463\n",
      "  count: 10003\n",
      "  countDistinct: 912\n",
      "  max: 2017-11-02 00:00:00\n",
      "  min: 2015-03-19 00:00:00\n",
      "model_name: word2vec\n",
      "model_weights_path: file:///datalake/models/products/word2vec\n",
      "trained_at: 2020-12-08 23:03:18.089839\n",
      "training: '{''model'': {''input_col'': ''text_cleaned'', ''stop_words'': ''english'',\n",
      "  ''features'': 128, ''lemmatization'': True}}'\n",
      "training_proc: dextra.dna.commons.processors.products.LearningEncoder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(last_training.asDict(recursive=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = C.io.stream.read(P.config.lakes.refined + '/issues.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_training = (\n",
    "    t.where(t.model_name == 'word2vec')\n",
    "     .orderBy(F.desc('trained_at'))\n",
    "     .limit(1)\n",
    "     .collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "encoder = PipelineModel.load(word2vec_training.model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>consumer_message</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>date_received</th>\n",
       "      <th>disputed</th>\n",
       "      <th>issue</th>\n",
       "      <th>product</th>\n",
       "      <th>resolution</th>\n",
       "      <th>state</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>ingested_at</th>\n",
       "      <th>tags_trusted_labels</th>\n",
       "      <th>tags_split</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>committed_at</th>\n",
       "      <th>text_cleaned_lemma</th>\n",
       "      <th>text_cleaned_words</th>\n",
       "      <th>text_cleaned_filtered</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>Hello My name is {hash} and I have a {hash} th...</td>\n",
       "      <td>26d89fd7bd44</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>False</td>\n",
       "      <td>Problems when you are unable to pay</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>GA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>300XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>hello my name is {hash} and i have a {hash} th...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>hello my name is {hash} and i have a {hash} th...</td>\n",
       "      <td>[hello, my, name, is, {hash}, and, i, have, a,...</td>\n",
       "      <td>[hello, name, {hash}, {hash}, santander, consu...</td>\n",
       "      <td>[-0.046171571916112535, -0.01197570159386557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>I have written several letters to the creditor...</td>\n",
       "      <td>89dbbe6ad0b5</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>True</td>\n",
       "      <td>Credit reporting company's investigation</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>OH</td>\n",
       "      <td>Investigation took too long</td>\n",
       "      <td>...</td>\n",
       "      <td>440XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>i have written several letters to the creditor...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>i have written several letters to the creditor...</td>\n",
       "      <td>[i, have, written, several, letters, to, the, ...</td>\n",
       "      <td>[written, several, letters, creditor, {hash}, ...</td>\n",
       "      <td>[-0.035483965111014086, 0.060496491012408546, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>This agency is reporting an account on my redi...</td>\n",
       "      <td>321a61586171</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>604XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>this agency is reporting an account on my redi...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>this agency is reporting an account on my redi...</td>\n",
       "      <td>[this, agency, is, reporting, an, account, on,...</td>\n",
       "      <td>[agency, reporting, account, redit, profile, b...</td>\n",
       "      <td>[-0.12961782080431777, -0.008926396335785586, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>In {hash}/{hash}/{hash} or {hash}/{hash}/{hash...</td>\n",
       "      <td>f11c4528f211</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>None</td>\n",
       "      <td>Fraud or scam</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "      <td>Untimely response</td>\n",
       "      <td>PA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>160XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>in {hash} {hash} {hash} or {hash} {hash} {hash...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>in {hash} {hash} {hash} or {hash} {hash} {hash...</td>\n",
       "      <td>[in, {hash}, {hash}, {hash}, or, {hash}, {hash...</td>\n",
       "      <td>[{hash}, {hash}, {hash}, {hash}, {hash}, {hash...</td>\n",
       "      <td>[-9.312533341299474e-06, -0.03235167523448849,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>In my previous complaint Equifax states \" Equi...</td>\n",
       "      <td>3fb5aa9ff928</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>False</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Reinserted previously deleted info</td>\n",
       "      <td>...</td>\n",
       "      <td>913XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>in my previous complaint equifax states equifa...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>in my previous complaint equifax states equifa...</td>\n",
       "      <td>[in, my, previous, complaint, equifax, states,...</td>\n",
       "      <td>[previous, complaint, equifax, states, equifax...</td>\n",
       "      <td>[-0.02981079175568572, -0.004501622056633961, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id                                   consumer_message  \\\n",
       "0  0052ac552c28  Hello My name is {hash} and I have a {hash} th...   \n",
       "1  00a844d52aec  I have written several letters to the creditor...   \n",
       "2  00ae385f4af9  This agency is reporting an account on my redi...   \n",
       "3  00da7e528dac  In {hash}/{hash}/{hash} or {hash}/{hash}/{hash...   \n",
       "4  010554da4e3a  In my previous complaint Equifax states \" Equi...   \n",
       "\n",
       "  customer_name date_received disputed  \\\n",
       "0  26d89fd7bd44    2017-01-30    False   \n",
       "1  89dbbe6ad0b5    2016-11-11     True   \n",
       "2  321a61586171    2016-10-27    False   \n",
       "3  f11c4528f211    2017-08-30     None   \n",
       "4  3fb5aa9ff928    2016-01-06    False   \n",
       "\n",
       "                                      issue  \\\n",
       "0       Problems when you are unable to pay   \n",
       "1  Credit reporting company's investigation   \n",
       "2                                     Other   \n",
       "3                             Fraud or scam   \n",
       "4    Incorrect information on credit report   \n",
       "\n",
       "                                             product               resolution  \\\n",
       "0                                      Consumer Loan  Closed with explanation   \n",
       "1                                   Credit reporting  Closed with explanation   \n",
       "2                                        Credit card  Closed with explanation   \n",
       "3  Money transfer, virtual currency, or money ser...        Untimely response   \n",
       "4                                   Credit reporting  Closed with explanation   \n",
       "\n",
       "  state                           sub_issue  ... zip_code  \\\n",
       "0    GA                                None  ...    300XX   \n",
       "1    OH         Investigation took too long  ...    440XX   \n",
       "2    IL                                None  ...    604XX   \n",
       "3    PA                                None  ...    160XX   \n",
       "4    CA  Reinserted previously deleted info  ...    913XX   \n",
       "\n",
       "                 ingested_at  tags_trusted_labels tags_split  \\\n",
       "0 2020-12-08 21:22:48.137401                False      train   \n",
       "1 2020-12-08 21:22:48.137401                False      train   \n",
       "2 2020-12-08 21:22:48.137401                False      train   \n",
       "3 2020-12-08 21:22:48.137401                False       test   \n",
       "4 2020-12-08 21:22:48.137401                False       test   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  hello my name is {hash} and i have a {hash} th...   \n",
       "1  i have written several letters to the creditor...   \n",
       "2  this agency is reporting an account on my redi...   \n",
       "3  in {hash} {hash} {hash} or {hash} {hash} {hash...   \n",
       "4  in my previous complaint equifax states equifa...   \n",
       "\n",
       "                committed_at  \\\n",
       "0 2020-12-08 21:24:36.162162   \n",
       "1 2020-12-08 21:24:36.162162   \n",
       "2 2020-12-08 21:24:36.162162   \n",
       "3 2020-12-08 21:24:36.162162   \n",
       "4 2020-12-08 21:24:36.162162   \n",
       "\n",
       "                                  text_cleaned_lemma  \\\n",
       "0  hello my name is {hash} and i have a {hash} th...   \n",
       "1  i have written several letters to the creditor...   \n",
       "2  this agency is reporting an account on my redi...   \n",
       "3  in {hash} {hash} {hash} or {hash} {hash} {hash...   \n",
       "4  in my previous complaint equifax states equifa...   \n",
       "\n",
       "                                  text_cleaned_words  \\\n",
       "0  [hello, my, name, is, {hash}, and, i, have, a,...   \n",
       "1  [i, have, written, several, letters, to, the, ...   \n",
       "2  [this, agency, is, reporting, an, account, on,...   \n",
       "3  [in, {hash}, {hash}, {hash}, or, {hash}, {hash...   \n",
       "4  [in, my, previous, complaint, equifax, states,...   \n",
       "\n",
       "                               text_cleaned_filtered  \\\n",
       "0  [hello, name, {hash}, {hash}, santander, consu...   \n",
       "1  [written, several, letters, creditor, {hash}, ...   \n",
       "2  [agency, reporting, account, redit, profile, b...   \n",
       "3  [{hash}, {hash}, {hash}, {hash}, {hash}, {hash...   \n",
       "4  [previous, complaint, equifax, states, equifax...   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.046171571916112535, -0.01197570159386557, ...  \n",
       "1  [-0.035483965111014086, 0.060496491012408546, ...  \n",
       "2  [-0.12961782080431777, -0.008926396335785586, ...  \n",
       "3  [-9.312533341299474e-06, -0.03235167523448849,...  \n",
       "4  [-0.02981079175568572, -0.004501622056633961, ...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = x.limit(5)\n",
    "s = encoder.transform(s)\n",
    "s = s.toPandas()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello my name is {hash} and i have a {hash} through santander consumer usa i got the truck back in {',\n",
       " 'hello my name is {hash} and i have a {hash} through santander consumer usar i got the truck back in ')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.text_cleaned[0][:LETTERS], s.text_cleaned_lemma[0][:LETTERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LETTERS = 100\n",
    "s.text_cleaned[0][:LETTERS] == s.text_cleaned_lemma[0][:LETTERS]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
