{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local environment.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "import dextra.dna.core as C\n",
    "import dextra.dna.commons as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = P.config.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_weights_path</th>\n",
       "      <th>training_proc</th>\n",
       "      <th>training</th>\n",
       "      <th>trained_at</th>\n",
       "      <th>date_received_stats</th>\n",
       "      <th>committed_at_stats</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>file:///datalake/models/products/word2vec</td>\n",
       "      <td>dextra.dna.commons.processors.products.Learnin...</td>\n",
       "      <td>{'model': {'input_col': 'text_cleaned', 'stop_...</td>\n",
       "      <td>2020-12-08 23:03:18.089839</td>\n",
       "      <td>(2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...</td>\n",
       "      <td>(2020-12-08 21:24:36.162162, 2020-12-08 21:24:...</td>\n",
       "      <td>[(861cbf751715, 2020-12-08 21:24:36.162162), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>file:///datalake/models/products/word2vec</td>\n",
       "      <td>dextra.dna.commons.processors.products.Learnin...</td>\n",
       "      <td>{'model': {'input_col': 'text_cleaned', 'stop_...</td>\n",
       "      <td>2020-12-08 23:36:43.753759</td>\n",
       "      <td>(2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...</td>\n",
       "      <td>(2020-12-08 21:24:36.162162, 2020-12-08 21:24:...</td>\n",
       "      <td>[(861cbf751715, 2020-12-08 21:24:36.162162), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                         model_weights_path  \\\n",
       "0   word2vec  file:///datalake/models/products/word2vec   \n",
       "1   word2vec  file:///datalake/models/products/word2vec   \n",
       "\n",
       "                                       training_proc  \\\n",
       "0  dextra.dna.commons.processors.products.Learnin...   \n",
       "1  dextra.dna.commons.processors.products.Learnin...   \n",
       "\n",
       "                                            training  \\\n",
       "0  {'model': {'input_col': 'text_cleaned', 'stop_...   \n",
       "1  {'model': {'input_col': 'text_cleaned', 'stop_...   \n",
       "\n",
       "                  trained_at  \\\n",
       "0 2020-12-08 23:03:18.089839   \n",
       "1 2020-12-08 23:36:43.753759   \n",
       "\n",
       "                                 date_received_stats  \\\n",
       "0  (2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...   \n",
       "1  (2015-03-19 00:00:00, 2017-11-02 00:00:00, 146...   \n",
       "\n",
       "                                  committed_at_stats  \\\n",
       "0  (2020-12-08 21:24:36.162162, 2020-12-08 21:24:...   \n",
       "1  (2020-12-08 21:24:36.162162, 2020-12-08 21:24:...   \n",
       "\n",
       "                                             records  \n",
       "0  [(861cbf751715, 2020-12-08 21:24:36.162162), (...  \n",
       "1  [(861cbf751715, 2020-12-08 21:24:36.162162), (...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PQT = P.config.lakes.models + '/logs/encoder_trainings.parquet'\n",
    "\n",
    "t = C.io.stream.read(PQT)\n",
    "t.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats from Last Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_training = (\n",
    "    t.drop('records')\n",
    "     .orderBy(F.desc('trained_at'))\n",
    "     .limit(1)\n",
    "     .collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committed_at_stats:\n",
      "  avg: 1607462676.1621423\n",
      "  count: 10003\n",
      "  countDistinct: 1\n",
      "  max: 2020-12-08 21:24:36.162162\n",
      "  min: 2020-12-08 21:24:36.162162\n",
      "date_received_stats:\n",
      "  avg: 1468604431.790463\n",
      "  count: 10003\n",
      "  countDistinct: 912\n",
      "  max: 2017-11-02 00:00:00\n",
      "  min: 2015-03-19 00:00:00\n",
      "model_name: word2vec\n",
      "model_weights_path: file:///datalake/models/products/word2vec\n",
      "trained_at: 2020-12-08 23:36:43.753759\n",
      "training: '{''model'': {''input_col'': ''text_cleaned'', ''stop_words'': ''english'',\n",
      "  ''features'': 128}}'\n",
      "training_proc: dextra.dna.commons.processors.products.LearningEncoder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(last_training.asDict(recursive=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = C.io.stream.read(P.config.lakes.refined + '/issues.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_training = (\n",
    "    t.where(t.model_name == 'word2vec')\n",
    "     .orderBy(F.desc('trained_at'))\n",
    "     .limit(1)\n",
    "     .collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "encoder = PipelineModel.load(word2vec_training.model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>consumer_message</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>date_received</th>\n",
       "      <th>disputed</th>\n",
       "      <th>issue</th>\n",
       "      <th>product</th>\n",
       "      <th>resolution</th>\n",
       "      <th>state</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>...</th>\n",
       "      <th>via</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>ingested_at</th>\n",
       "      <th>tags_trusted_labels</th>\n",
       "      <th>tags_split</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>committed_at</th>\n",
       "      <th>text_cleaned_words</th>\n",
       "      <th>text_cleaned_filtered</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>Hello My name is {hash} and I have a {hash} th...</td>\n",
       "      <td>26d89fd7bd44</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>False</td>\n",
       "      <td>Problems when you are unable to pay</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>GA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Web</td>\n",
       "      <td>300XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>hello my name is {hash} and i have a {hash} th...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>[hello, my, name, is, {hash}, and, i, have, a,...</td>\n",
       "      <td>[hello, name, {hash}, {hash}, santander, consu...</td>\n",
       "      <td>[0.042588631013551585, 0.040190241351061, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>I have written several letters to the creditor...</td>\n",
       "      <td>89dbbe6ad0b5</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>True</td>\n",
       "      <td>Credit reporting company's investigation</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>OH</td>\n",
       "      <td>Investigation took too long</td>\n",
       "      <td>...</td>\n",
       "      <td>Web</td>\n",
       "      <td>440XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>i have written several letters to the creditor...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>[i, have, written, several, letters, to, the, ...</td>\n",
       "      <td>[written, several, letters, creditor, {hash}, ...</td>\n",
       "      <td>[0.05852093231527412, -0.08493632040521566, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>This agency is reporting an account on my redi...</td>\n",
       "      <td>321a61586171</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Web</td>\n",
       "      <td>604XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>this agency is reporting an account on my redi...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>[this, agency, is, reporting, an, account, on,...</td>\n",
       "      <td>[agency, reporting, account, redit, profile, b...</td>\n",
       "      <td>[0.12804793007671833, -0.03408676184092958, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>In {hash}/{hash}/{hash} or {hash}/{hash}/{hash...</td>\n",
       "      <td>f11c4528f211</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>None</td>\n",
       "      <td>Fraud or scam</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "      <td>Untimely response</td>\n",
       "      <td>PA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Web</td>\n",
       "      <td>160XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>in {hash} {hash} {hash} or {hash} {hash} {hash...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>[in, {hash}, {hash}, {hash}, or, {hash}, {hash...</td>\n",
       "      <td>[{hash}, {hash}, {hash}, {hash}, {hash}, {hash...</td>\n",
       "      <td>[0.05250623404648841, 0.027649868460445613, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>In my previous complaint Equifax states \" Equi...</td>\n",
       "      <td>3fb5aa9ff928</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>False</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Reinserted previously deleted info</td>\n",
       "      <td>...</td>\n",
       "      <td>Web</td>\n",
       "      <td>913XX</td>\n",
       "      <td>2020-12-08 21:22:48.137401</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>in my previous complaint equifax states equifa...</td>\n",
       "      <td>2020-12-08 21:24:36.162162</td>\n",
       "      <td>[in, my, previous, complaint, equifax, states,...</td>\n",
       "      <td>[previous, complaint, equifax, states, equifax...</td>\n",
       "      <td>[0.16846882887241407, -0.08434288474026977, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id                                   consumer_message  \\\n",
       "0  0052ac552c28  Hello My name is {hash} and I have a {hash} th...   \n",
       "1  00a844d52aec  I have written several letters to the creditor...   \n",
       "2  00ae385f4af9  This agency is reporting an account on my redi...   \n",
       "3  00da7e528dac  In {hash}/{hash}/{hash} or {hash}/{hash}/{hash...   \n",
       "4  010554da4e3a  In my previous complaint Equifax states \" Equi...   \n",
       "\n",
       "  customer_name date_received disputed  \\\n",
       "0  26d89fd7bd44    2017-01-30    False   \n",
       "1  89dbbe6ad0b5    2016-11-11     True   \n",
       "2  321a61586171    2016-10-27    False   \n",
       "3  f11c4528f211    2017-08-30     None   \n",
       "4  3fb5aa9ff928    2016-01-06    False   \n",
       "\n",
       "                                      issue  \\\n",
       "0       Problems when you are unable to pay   \n",
       "1  Credit reporting company's investigation   \n",
       "2                                     Other   \n",
       "3                             Fraud or scam   \n",
       "4    Incorrect information on credit report   \n",
       "\n",
       "                                             product               resolution  \\\n",
       "0                                      Consumer Loan  Closed with explanation   \n",
       "1                                   Credit reporting  Closed with explanation   \n",
       "2                                        Credit card  Closed with explanation   \n",
       "3  Money transfer, virtual currency, or money ser...        Untimely response   \n",
       "4                                   Credit reporting  Closed with explanation   \n",
       "\n",
       "  state                           sub_issue  ...  via zip_code  \\\n",
       "0    GA                                None  ...  Web    300XX   \n",
       "1    OH         Investigation took too long  ...  Web    440XX   \n",
       "2    IL                                None  ...  Web    604XX   \n",
       "3    PA                                None  ...  Web    160XX   \n",
       "4    CA  Reinserted previously deleted info  ...  Web    913XX   \n",
       "\n",
       "                 ingested_at tags_trusted_labels tags_split  \\\n",
       "0 2020-12-08 21:22:48.137401               False      train   \n",
       "1 2020-12-08 21:22:48.137401               False      train   \n",
       "2 2020-12-08 21:22:48.137401               False      train   \n",
       "3 2020-12-08 21:22:48.137401               False       test   \n",
       "4 2020-12-08 21:22:48.137401               False       test   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  hello my name is {hash} and i have a {hash} th...   \n",
       "1  i have written several letters to the creditor...   \n",
       "2  this agency is reporting an account on my redi...   \n",
       "3  in {hash} {hash} {hash} or {hash} {hash} {hash...   \n",
       "4  in my previous complaint equifax states equifa...   \n",
       "\n",
       "                committed_at  \\\n",
       "0 2020-12-08 21:24:36.162162   \n",
       "1 2020-12-08 21:24:36.162162   \n",
       "2 2020-12-08 21:24:36.162162   \n",
       "3 2020-12-08 21:24:36.162162   \n",
       "4 2020-12-08 21:24:36.162162   \n",
       "\n",
       "                                  text_cleaned_words  \\\n",
       "0  [hello, my, name, is, {hash}, and, i, have, a,...   \n",
       "1  [i, have, written, several, letters, to, the, ...   \n",
       "2  [this, agency, is, reporting, an, account, on,...   \n",
       "3  [in, {hash}, {hash}, {hash}, or, {hash}, {hash...   \n",
       "4  [in, my, previous, complaint, equifax, states,...   \n",
       "\n",
       "                               text_cleaned_filtered  \\\n",
       "0  [hello, name, {hash}, {hash}, santander, consu...   \n",
       "1  [written, several, letters, creditor, {hash}, ...   \n",
       "2  [agency, reporting, account, redit, profile, b...   \n",
       "3  [{hash}, {hash}, {hash}, {hash}, {hash}, {hash...   \n",
       "4  [previous, complaint, equifax, states, equifax...   \n",
       "\n",
       "                                            features  \n",
       "0  [0.042588631013551585, 0.040190241351061, 0.04...  \n",
       "1  [0.05852093231527412, -0.08493632040521566, -0...  \n",
       "2  [0.12804793007671833, -0.03408676184092958, -0...  \n",
       "3  [0.05250623404648841, 0.027649868460445613, 0....  \n",
       "4  [0.16846882887241407, -0.08434288474026977, -0...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = x.limit(5)\n",
    "s = encoder.transform(s)\n",
    "\n",
    "s.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    normalizer = Normalizer(inputCol='features', outputCol='features_norm')\n",
    "    return normalizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = normalize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_udf = F.udf(lambda x,y: float(x.dot(y)), types.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0052ac552c28</td>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00a844d52aec</td>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00ae385f4af9</td>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00da7e528dac</td>\n",
       "      <td>010554da4e3a</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              i             j  dot\n",
       "0  0052ac552c28  00a844d52aec -0.1\n",
       "1  0052ac552c28  00ae385f4af9  0.0\n",
       "2  0052ac552c28  00da7e528dac  0.7\n",
       "3  0052ac552c28  010554da4e3a -0.1\n",
       "4  00a844d52aec  00ae385f4af9  0.5\n",
       "5  00a844d52aec  00da7e528dac -0.1\n",
       "6  00a844d52aec  010554da4e3a  0.7\n",
       "7  00ae385f4af9  00da7e528dac -0.1\n",
       "8  00ae385f4af9  010554da4e3a  0.6\n",
       "9  00da7e528dac  010554da4e3a -0.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s.alias('i')\n",
    "  .join(s.alias(\"j\"), F.col(\"i.complaint_id\") < F.col(\"j.complaint_id\"))\\\n",
    "  .select(\n",
    "      F.col(\"i.complaint_id\").alias(\"i\"), \n",
    "      F.col(\"j.complaint_id\").alias(\"j\"),\n",
    "      dot_udf(\"i.features_norm\", \"j.features_norm\").alias(\"dot\"))\n",
    "  .sort(\"i\", \"j\")\n",
    "  .toPandas()\n",
    "  .round(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
